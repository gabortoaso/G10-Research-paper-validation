{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50eb1355",
      "metadata": {
        "id": "50eb1355"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.layers.core import Dense, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "from keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import data**"
      ],
      "metadata": {
        "id": "nXwmMiUHVmN1"
      },
      "id": "nXwmMiUHVmN1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0f4c486",
      "metadata": {
        "id": "b0f4c486"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "for file in os.listdir(\"sample_data/\"): # original: \"reuters_data/\"\n",
        "    if file.endswith('.sgm'): # it is important for GoogleColab\n",
        "        filename = os.path.join(\"sample_data\", file) # original: \"reuters_data\"\n",
        "        f = open(filename, 'r', encoding='utf-8', errors='ignore')\n",
        "        dataFile = f.read()\n",
        "        \n",
        "        soup = BeautifulSoup(dataFile, 'html.parser')\n",
        "        contents = soup.findAll('title')\n",
        "        \n",
        "        for content in contents:\n",
        "            documents.append(content.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of documents: {}'.format(len(documents)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwFHnhJ6YrPG",
        "outputId": "f7b57198-b7eb-4d73-def2-2e91f9b0f0cb"
      },
      "id": "jwFHnhJ6YrPG",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 20841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2f9549e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f9549e3",
        "outputId": "326615ba-644b-41cb-c6a1-020dc5ff6be8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CHRYSLER <C> LATE MARCH U.S. CAR SALES UP',\n",
              " 'WALL STREET STOCKS/COMPAQ COMPUTER <CPQ>',\n",
              " 'NORANDA SETS TEMPORARY MINE SHUTDOWN',\n",
              " 'CANADA BUDGET DEFICIT RISES IN JANUARY',\n",
              " 'CIS TECHNOLOGIES<CIH> TO SELL SHARES TO SWISS CO',\n",
              " 'COPLEY PROPERTIES INC <COP> INCREASES DIVIDEND',\n",
              " 'COLOMBIAN INFLATION STABLE AT AROUND 20 PCT',\n",
              " 'FHLBB SAYS MORTGAGE RATES CONTINUE DECLINE',\n",
              " 'NYFE SEAT SELLS FOR 1,500 DLRS',\n",
              " 'CANADIAN MONEY SUPPLY M-1 FALLS 291 MLN DLRS IN WEEK, BANK OF CANADA SAID\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "documents[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Join the documents**"
      ],
      "metadata": {
        "id": "fRsdiodgY4er"
      },
      "id": "fRsdiodgY4er"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9e5894ab",
      "metadata": {
        "id": "9e5894ab"
      },
      "outputs": [],
      "source": [
        "data = \"\"\n",
        "for d in documents:\n",
        "    data += d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a3a635c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3a635c4",
        "outputId": "05acfbee-649d-4bae-f61a-9e2df8b666c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data: 941529\n"
          ]
        }
      ],
      "source": [
        "print('Number of data: {}'.format(len(data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3ffe6795",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ffe6795",
        "outputId": "7832a0ac-c514-44b8-9a13-85ad731e8329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data: 939549\n",
            "CHRYSLER <C> LATE MARCH U.S. CAR SALES UPWALL STREET STOCKS/COMPAQ COMPUTER <CPQ>NORANDA SETS TEMPOR\n"
          ]
        }
      ],
      "source": [
        "# improve punctuation\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
        "print('Number of data: {}'.format(len(data)))\n",
        "print(data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
        "data = data.translate(translator)\n",
        "\n",
        "print(data[:100])"
      ],
      "metadata": {
        "id": "CNRiSJsMtwQu",
        "outputId": "6095ef11-f8e7-4739-ee36-6c8e95c76c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CNRiSJsMtwQu",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHRYSLER  C  LATE MARCH U S  CAR SALES UPWALL STREET STOCKS COMPAQ COMPUTER  CPQ NORANDA SETS TEMPOR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "225b3c6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "225b3c6b",
        "outputId": "a7fbc75f-9424-4ec1-f6e0-d698119c4290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[680, 200, 314, 67, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded_data = tokenizer.texts_to_sequences([data])[0]\n",
        "print(len(encoded_data))\n",
        "encoded_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "cff5b658",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cff5b658",
        "outputId": "a8f55b6e-6b4c-4b86-f74e-b0321895739f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 30874\n"
          ]
        }
      ],
      "source": [
        "# determine the vocabulary size\n",
        "unique_words = tokenizer.word_index\n",
        "# unique_words = np.unique(words) # alternative version\n",
        "vocab_size = len(unique_words) + 1  # 0 is reserved for padding so that's why we added 1\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "metadata": {
        "id": "_dPJH9Brwh9L"
      },
      "id": "_dPJH9Brwh9L",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, we need to create sequences of words to fit the model with one word as input and one word as output.**"
      ],
      "metadata": {
        "id": "PYLR_W62b3lm"
      },
      "id": "PYLR_W62b3lm"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "858f3ef5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "858f3ef5",
        "outputId": "cecaa0e3-4102-45d0-b8b3-c680367f036b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 140095\n"
          ]
        }
      ],
      "source": [
        "# create word -> word sequences\n",
        "WORD_LENGTH = 5\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(1, len(encoded_data) - WORD_LENGTH):\n",
        "    prev_words.append(encoded_data[i:i + WORD_LENGTH])\n",
        "    next_words.append(encoded_data[i + WORD_LENGTH])\n",
        "print('Total Sequences: %d' % len(prev_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running this piece shows that we have a total of 139.101 input-output pairs to train the network**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jAuVDQF9ceTs"
      },
      "id": "jAuVDQF9ceTs"
    },
    {
      "cell_type": "code",
      "source": [
        "# list(len(prev_words)[:5]) # [input, output]"
      ],
      "metadata": {
        "id": "MNb-LdgdcqSZ"
      },
      "id": "MNb-LdgdcqSZ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**We can then split the sequences into input (X) and output elements (y)**\n",
        "\n"
      ],
      "metadata": {
        "id": "kMClupvlcdWq"
      },
      "id": "kMClupvlcdWq"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f0fb1be0",
      "metadata": {
        "id": "f0fb1be0"
      },
      "outputs": [],
      "source": [
        "# split into X and y elements\n",
        "X = prev_words\n",
        "X = np.array(X)\n",
        "Y = next_words\n",
        "Y = np.array(Y)\n",
        "\n",
        "# X = np.zeros((len(prev_words), WORD_LENGTH, vocab_size), dtype=bool)\n",
        "# Y = np.zeros((len(next_words), vocab_size), dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6f323b68",
      "metadata": {
        "id": "6f323b68",
        "outputId": "f8b975ca-5be1-4f3c-de89-8b961e80bc51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 200  314   67   13    2]\n",
            " [ 314   67   13    2  156]\n",
            " [  67   13    2  156   53]\n",
            " [  13    2  156   53 7868]\n",
            " [   2  156   53 7868  395]]\n",
            "[ 156   53 7868  395  168]\n"
          ]
        }
      ],
      "source": [
        "print(X[:5])\n",
        "print(Y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "101d961d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "101d961d",
        "outputId": "25f3a37e-2fe0-4d72-927d-b2f42c027dc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# one hot encode outputs\n",
        "Y = to_categorical(Y, num_classes=vocab_size)\n",
        "# define model\n",
        "Y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the model**"
      ],
      "metadata": {
        "id": "9-SgDZVKd_IL"
      },
      "id": "9-SgDZVKd_IL"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b459da0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b459da0b",
        "outputId": "8e0ac9b5-47c0-4d13-957a-3dcafbd2132d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 10)             308740    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                12200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30874)             1574574   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,895,514\n",
            "Trainable params: 1,895,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=1)) # original: 5\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "F1eNfS9cebdM"
      },
      "id": "F1eNfS9cebdM"
    },
    {
      "cell_type": "code",
      "source": [
        "# fit network\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "\n",
        "# compile network\n",
        "#### since labels are INTEGERS, we need to changed from loss='categorical_crossentropy'!!!\n",
        "#### If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss.\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # optimizer ='adam'\n",
        "history = model.fit(X, Y, batch_size=50, epochs=20, shuffle=True).history\n",
        "\n",
        "## Alternative versions\n",
        "# history = model.fit(X, Y, validation_split=0.05, batch_size=50, epochs=20, shuffle=True).history\n",
        "# model.fit(X, Y, epochs=100)\n",
        "# model.fit(X, y, epochs=150, batch_size=64, callbacks=[checkpoint, reduce, tensorboard_Visualization])"
      ],
      "metadata": {
        "id": "Pjty_axoePeu"
      },
      "id": "Pjty_axoePeu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save trained model**"
      ],
      "metadata": {
        "id": "QxgsBCrwtECi"
      },
      "id": "QxgsBCrwtECi"
    },
    {
      "cell_type": "code",
      "source": [
        "# After successful training, we will save the trained model and just load it back as needed.\n",
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "\n",
        "model = load_model('keras_next_word_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "A2ioJcaGtEN4"
      },
      "id": "A2ioJcaGtEN4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**\n",
        "Using saved model:\n",
        "- we input the sample as a feature vector\n",
        "- we convert the input string to a single feature vector"
      ],
      "metadata": {
        "id": "XsrX16ketfZq"
      },
      "id": "XsrX16ketfZq"
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, vocab_size))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)\n",
        "        x[0, t, unique_word_index[word]] = 1\n",
        "    return x\n",
        "prepare_input(\"HOSPITAL CORP SAYS IT RECEIVED 47 DLR A SHARE OFFER FROM INVESTOR GROUP\".lower())"
      ],
      "metadata": {
        "id": "4UPDwpgBtfkF"
      },
      "id": "4UPDwpgBtfkF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To choose the best possible \"n\" words after the prediction from the model ...\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "metadata": {
        "id": "fmfAeTHUt5aL"
      },
      "id": "fmfAeTHUt5aL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function predict_completions to predict and return the list of \"n\" predicted words.\n",
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ],
      "metadata": {
        "id": "r75h3atZuDxS"
      },
      "id": "r75h3atZuDxS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use tokenizer.tokenize fo removing the punctuations and also we choose 5 first words because our predicts base on 5 previous words.\n",
        "q =  \"GILLETTE CANADA ISSUES 70 MLN STG BOND\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "metadata": {
        "id": "Cv5GjUyDuaNp"
      },
      "id": "Cv5GjUyDuaNp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Prediction script**"
      ],
      "metadata": {
        "id": "H41rOg1XpXUl"
      },
      "id": "H41rOg1XpXUl"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model and tokenizer\n",
        "\n",
        "model = history\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "    \"\"\"\n",
        "        In this function we are using the tokenizer and models trained\n",
        "        and we are creating the sequence of the text entered and then\n",
        "        using our model to predict and return the the predicted word.\n",
        "    \n",
        "    \"\"\"\n",
        "    for i in range(3):\n",
        "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "        sequence = np.array(sequence)\n",
        "        \n",
        "        preds = model.predict_classes(sequence)\n",
        "#         print(preds)\n",
        "        predicted_word = \"\"\n",
        "        \n",
        "        for key, value in tokenizer.word_index.items():\n",
        "            if value == preds:\n",
        "                predicted_word = key\n",
        "                break\n",
        "        \n",
        "        print(predicted_word)\n",
        "        return predicted_word"
      ],
      "metadata": {
        "id": "jVlQUV23pa6X"
      },
      "id": "jVlQUV23pa6X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    We are testing our model and we will run the model\n",
        "    until the user decides to stop the script.\n",
        "    While the script is running we try and check if \n",
        "    the prediction can be made on the text. If no\n",
        "    prediction can be made we just continue.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# text1 = \"at the dull\"\n",
        "# text2 = \"collection of textile\"\n",
        "# text3 = \"what a strenuous\"\n",
        "# text4 = \"stop the script\"\n",
        "\n",
        "while(True):\n",
        "\n",
        "    text = input(\"Enter your line: \")\n",
        "    \n",
        "    if text == \"stop the script\":\n",
        "        print(\"Ending The Program.....\")\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        try:\n",
        "            text = text.split(\" \")\n",
        "            text = text[-1]\n",
        "\n",
        "            text = ''.join(text)\n",
        "            Predict_Next_Words(model, tokenizer, text)\n",
        "            \n",
        "        except:\n",
        "            continue"
      ],
      "metadata": {
        "id": "LxZ-ZlCkpgZ0",
        "outputId": "0c39010f-4520-4860-a51a-3a940d7c23d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LxZ-ZlCkpgZ0",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your line: ilona\n",
            "Enter your line: ISRAELI HELICOPTERS\n",
            "Enter your line: GILLETTE CANADA ISSUES\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}